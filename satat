1. Problem Statement
The mind reader machine developed here is motivated by Shannon’s "A Mind-reading(?)
Machine"(1953) and Hagelbarger's "SEER, A SEquence Extrapolating Robot"(1956). In this game the user
is playing against the machine, the user selects a bit (in this implementation it’s the right and left keys)
and the machine is trying to predict which key the user will click. If the machine guesses correctly it gets
a point, and otherwise the user gets a point.
If both players make their selection from a “real” i.i.d. process, they have equal chance of winning.
However, for humans it’s extremely hard to produce i.i.d. sequences, this is exactly what the machine is
aiming to exploit.

2. Game Tutorial
The game is developed in Python. To play the game run the main.py file. In that file you can choose
the game target (default value is 50), and to ask the computer to generate i.i.d sequence for the user (this
will be discussed later).
Once the game is lunched the user should click either the left or right keys to make his selection, the
computer is making its selection in the background. The current score of the game is presented in a Matlab
figure, as seen below.

The figure shows the current scores towards the game’s target.
During the game the user can exit any time by hitting ‘q’. The user can also choose the cheat by hitting
‘c’, this will open a second figure with current algorithm status and algorithm decisions.

The game ends when the first player reaches the game goal, then the game summary figure is shown
(the same figure is shown during “cheating” mode).

Game summary figure. From top to bottom: The time evolving score. The algorithm’s error rate. The exponential
weights evolution for aggregated predictors based on type. The current exponential weights for all predictors, the
title provides the decision bias and the actual prediction.

3. Algorithm Description
The algorithm which defines the computer’s move is based on the Experts Setting as we learned in
the class. The experts are a set of predictors (described later) which attempt to predict the next user move
based on previous moves. The next subsection describes the various predictors, and will follow by a
description of the exponential weights algorithm to aggregate these predictors.
First, we define some notations. Right key is assigned +1, left key is assigned −1. The user strokes is
denoted by 𝑢(1. . 𝑛), and the algorithms predictions (strokes) is defined by 𝑏(1. . 𝑛), 𝑛 is the current game
turn. 𝑇 is the game target.
The predictors can operate on the immediate keystrokes sequence 𝑢(1. . 𝑛), or on the flipping
sequence defined by:
1 𝑢(𝑛) == 𝑢(𝑛 − 1)
𝑓(𝑛) = {
−1
𝑒𝑙𝑠𝑒
this sequence indicates flipping of bits, rather than the bits themselves.

3.1.

Predictors

3.1.1. Bias Predictor
The bias predictor tracks the user strokes and searches for specific bias in the sequence (for example
tends to hit more right key). This predictor can be tuned to search for bias in a given history length 𝑚, this
allows to create multiple predictors each searching for bias with different memory. The expert prediction
is defined by:

𝑚

1
𝑃𝐵,𝑢 (𝑛 + 1) = ∑ 𝑢(𝑛 − 𝑖)
𝑚
𝑖=1

In my implementation I used four Bias Predictors with memories: 𝑚 = 5, 10, 15, 20.

3.1.2. Flipping Bias Predictor
This essentially the same implementation of the Bias Predictor, but this predictor searches for bias in
flipping sequence (for example hitting the right key 𝑘 times followed by 𝑘 times left key has zero mean,
but the flipping sequence shows significant bias to hit the same key multiple times). This predictor can
also operate on a given history 𝑚, such that:
𝑚

1
𝑃𝐵,𝑓 (𝑛 + 1) = 𝑢(𝑛) ∑ 𝑓(𝑛 − 𝑖)
𝑚
𝑖=1

In my implementation I used four Flipping Bias Predictors with memories: 𝑚 = 5, 10, 15, 20.

3.1.3. Pattern Predictor
This predictor detects keystroke patterns (for example [𝑅, 𝐿, 𝐿, 𝑅, 𝐿, 𝐿, … ] , where 𝑅, 𝐿 stands for right
and left keys respectively). It searches for pattern length 𝑚 .This predictor operates by the following
procedure:
1.

𝑝𝑎𝑡𝑡𝑒𝑟𝑛 = 𝑢(𝑛 − 𝑚 . . 𝑛)

2.

𝑖 = 𝑛, 𝑠𝑐𝑜𝑟𝑒𝑢 = 0

3.

𝑤ℎ𝑖𝑙𝑒

𝑝𝑎𝑡𝑡𝑒𝑟𝑛 == 𝑢(𝑖 − 𝑚. . 𝑖)

4.

𝑠𝑐𝑜𝑟𝑒𝑢 = 𝑠𝑐𝑜𝑟𝑒𝑢 + 1

5.

𝑝𝑎𝑡𝑡𝑒𝑟𝑛 = 𝑠ℎ𝑖𝑓𝑡(𝑝𝑎𝑡𝑡𝑒𝑟𝑛)

6.

𝑖 =𝑖−1

7.

end

where 𝑠ℎ𝑖𝑓𝑡(∙) produces a cyclic shift of the input.
The prediction is defined by:
𝑃𝑃,𝑢 = 𝑢(𝑛 − 𝑚)

min{𝑠𝑐𝑜𝑟𝑒𝑢 , 2𝑚}
2𝑚

where the score defines the confidence of the prediction, here I defined an ideal case as a situation where
the pattern repeats itself two times.
In my implementation I choose to search for patterns of lengths: 𝑚 = 2,3,4,5,6.

3.1.4. Flipping Pattern Detector
This predictor is implemented exactly as the previous predictor, but it operates on the flipping
sequence instead (it searches for sequences such as: [𝑆, 𝑆, 𝐹, 𝑆, 𝑆, 𝐹, … ], where 𝑆, 𝐹 stands for same key
and flipping respectively). The scoring algorithm operates exactly the same as the regular pattern
predictor, with replacing the sequence 𝑢(1. . 𝑛) by 𝑓(1. . 𝑛), and produces 𝑠𝑐𝑜𝑟𝑒𝑓 . The prediction is then:
min{𝑠𝑐𝑜𝑟𝑒𝑓 , 2𝑚}
𝑃𝑃,𝑓 = 𝑢(𝑛 − 𝑚)
2𝑚

Similar to the previous predictor, the patterns lengths searched for are: 𝑚 = 2,3,4,5,6.

3.1.5. Shannon Inspired Predictor (user reaction predictor)
In his paper, Shannon proposed the user reacts to winning and losing. He proposed the user reactions
can be characterized in 8 ways:
1.
2.
3.
4.
5.
6.
7.
8.

User wins, played the same, wins again, he may play the same of differently.
User wins, played the same, losses, he may play the same of differently.
User wins, played differently, wins again, he may play the same of differently.
User wins, played differently, losses, he may play the same of differently.
User losses, played the same, wins again, he may play the same of differently.
User losses, played the same, losses, he may play the same of differently.
User losses, played differently, wins again, he may play the same of differently.
User losses, played differently, losses, he may play the same of differently.

While previous predictors ignored the winning / losing aspect of the game, this detector introduces
this emotional aspect. In the context of previous predictors, this predictor operates on the flipping
sequence 𝑓(1. . 𝑛) and on the user win/loss sequence defined by:
1 𝑢(𝑛) ≠ 𝑏(𝑛)
𝑤𝑢 (𝑛) = {
−1
𝑒𝑙𝑠𝑒
In my implementation I extended the predictor to operate on user with variable memory (Shannon’s
proposal assumed the user has a memory length of 𝑚 = 1), for example the user might have a longer
memory. This predictor is implemented by keeping a state machine to track how the user played the last
time he was in a similar situation, the total number of states is just 22𝑚+1 . Here, 𝑚 counts the memory
of results to previous player attempts, and the extra 1 counts first win/loss.
Each time the user plays, the predictor updates the state machine 𝑆𝑚 by the following procedure:
1. Based on 𝑓(𝑛 − 𝑚 − 1 … 𝑛 − 1), and 𝑤𝑢 (𝑛 − 𝑚 − 2 … 𝑛 − 1) map to the appropriate state
index 𝑖.
2. If 𝑆𝑚 (𝑖) == 0 then:
%i.e. no meaningful history
(𝑖)
𝑆𝑚 = 0.3 𝑓(𝑛)
%update the state with low score
3. Else if 𝑆𝑚 (𝑖) 𝑓(𝑛) == 0.3 %i.e. this is the second time the user is doing the same thing
𝑆𝑚 (𝑖) = 0.8 𝑓(𝑛)
%update the state with higher score
4. Else if 𝑆𝑚 (𝑖) 𝑓(𝑛) == 0.8 %i.e. this is the third time the user is doing the same thing
𝑆𝑚 (𝑖) = 𝑓(𝑛)
%update the state with highest score
5. Else
%i.e. the user played different then the prediction
𝑆𝑚 (𝑖) = 0
%update the state with zero confidence
The motivation behind these updates is to increase confidence of the decision if the user reacts the
same way as he did previously when encountered a similar situation.
Finally, the prediction of the next step is defined by: 𝑓(𝑛 − 𝑚. . 𝑛), and 𝑤𝑢 (𝑛 − 𝑚 − 1. . 𝑛) map to
the appropriate state index 𝑖, and predicting 𝑃𝑅 (𝑛 + 1) = 𝑆𝑚 (𝑖).
In my implementation I choose these memory lengths: 𝑚 = [0,1,2,3]. The 𝑚 = 0 case corresponds
to a user that purely reacts to winning or losing, without memory of what brought the win/loss (for

example whenever losing flip the decision). While the longer memory predictors include the shorter ones,
due to the non-linear update when the user reacted different than expected, the short memory predictors
would react faster to change in behavior.

3.1.6. Hagelbarger's Inspired Predictor (“emotional” bot algorithm)
Hagelbarger proposed a very similar algorithm to Shannon’s, basically, he proposed the machine
should react to winning or losing and play the next step based on the last it encountered such a case.
Essentially this is exactly the same implementation as the previous approach, but operating on the
machine’s strokes and win/loss sequence:
1 𝑏(𝑛) == 𝑏(𝑛 − 1)
𝑏𝑓 (𝑛) = {
−1
𝑒𝑙𝑠𝑒
1 𝑢(𝑛) == 𝑏(𝑛)
𝑤𝑏 (𝑛) = {
−1
𝑒𝑙𝑠𝑒
For this implementation I used the same memory lengths as the previous example.

3.2.

Predictors aggregation, and algorithm decision

There are a total of 26 predictors in my implementation (the number can easily be changed by adding
or removing memory lengths, this can be done in the game_parameters.m file). The predictors results are
aggregated with the exponential weights algorithm. We define an index 𝑗 = 1. . 𝑁 to run over all 𝑁 = 26
predictors, such that 𝑃𝑗 (𝑛) is the 𝑗 − 𝑡ℎ expert prediction for time 𝑛. First we use “soft-max” to weigh all
the predictors based on their performance:
exp{−𝜂 ∑𝑛𝑠=1|𝑢(𝑠) − 𝑃𝑗 (𝑠)|}
𝑊𝑗 (𝑛 + 1) = 𝑁
∑𝑗=1 exp{−𝜂 ∑𝑛𝑠=1|𝑢(𝑠) − 𝑃𝑗 (𝑠)|}
log 𝑁

with: 𝜂 = √2𝑇−1 .
This allows to choose a bias for the current decision:
𝑁

𝑞𝑡 (𝑛 + 1) = ∑ 𝑊𝑗 (𝑛 + 1) 𝑃𝑗 (𝑛 + 1)
𝑗=1

Finally, the algorithm takes a random decision with bias 𝑞𝑡 such that:
𝑏(𝑛 + 1) = 𝑅𝑎𝑑𝑒𝑚𝑎𝑐ℎ𝑒𝑟 𝑤𝑖𝑡ℎ 𝑚𝑒𝑎𝑛 𝑞𝑡

4. Results
The game was played by several users, here are a couple examples of the final results:

Here are results for a computational random user playing against the algorithm (game target is
500):

We note that the game lasted for almost the maximum duration (997 turns out possible 999), that
the error rate is 50%, and that there is no preferred expert.

5. Brief Code Overview
Here is a short description of the code structure:

1. action.py contains a description of the actions available to each user
2. baseline.py contains an implementation of the baseline algorithm described above
3. bush_mosteller.py contains an implementation of the bush mosteller algorithm
4. player.py contains code for each player, including logic on making a move
5. main.py contains code that wraps everything together

6. Future Work
There are several things to explore in the context of this work:


Predictions:
o The Shannon and Hagelbarger detectors can be implemented on the direct key
strokes sequence.
o All detectors can be explored with other parameters (memory length, ways to score
the predictions).
o It would be interesting to explore other reactive based predictors (how people
respond to winning or losing).
o Reducing the number of experts to expedite learning (decreasing log 𝑁 /2𝑇).





User behaviors:
o It seems that users behave different the first time they play the game and from a (not
statistically meaningful) observation it appears they do better the first time they play.
I suspect this is because they are less engaged the first time, and so can produce more
random sequences.
o It would be interesting to explore and understand how users react to this game, for
example do people have some common behavior model (similar to what Shannon
suggested). Putting this game online can help to evaluate this.
Other ways to perform the task:
o Is it possible to solve this problem in the context of Cover’s algorithm? What are the
desired sequences? Can we learn them from many players?
o If the user produces non-random sequence, it means it’s compressible, that can allow
to predict the next bit.

