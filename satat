1. Problem Statement
The mind reader machine developed here is motivated by Shannonâ€™s "A Mind-reading(?)
Machine"(1953) and Hagelbarger's "SEER, A SEquence Extrapolating Robot"(1956). In this game the user
is playing against the machine, the user selects a bit (in this implementation itâ€™s the right and left keys)
and the machine is trying to predict which key the user will click. If the machine guesses correctly it gets
a point, and otherwise the user gets a point.
If both players make their selection from a â€œrealâ€ i.i.d. process, they have equal chance of winning.
However, for humans itâ€™s extremely hard to produce i.i.d. sequences, this is exactly what the machine is
aiming to exploit.

2. Game Tutorial
The game is developed in Python. To play the game run the main.py file. In that file you can choose
the game target (default value is 50), and to ask the computer to generate i.i.d sequence for the user (this
will be discussed later).
Once the game is lunched the user should click either the left or right keys to make his selection, the
computer is making its selection in the background. The current score of the game is presented in a Matlab
figure, as seen below.

The figure shows the current scores towards the gameâ€™s target.
During the game the user can exit any time by hitting â€˜qâ€™. The user can also choose the cheat by hitting
â€˜câ€™, this will open a second figure with current algorithm status and algorithm decisions.

The game ends when the first player reaches the game goal, then the game summary figure is shown
(the same figure is shown during â€œcheatingâ€ mode).

Game summary figure. From top to bottom: The time evolving score. The algorithmâ€™s error rate. The exponential
weights evolution for aggregated predictors based on type. The current exponential weights for all predictors, the
title provides the decision bias and the actual prediction.

3. Algorithm Description
The algorithm which defines the computerâ€™s move is based on the Experts Setting as we learned in
the class. The experts are a set of predictors (described later) which attempt to predict the next user move
based on previous moves. The next subsection describes the various predictors, and will follow by a
description of the exponential weights algorithm to aggregate these predictors.
First, we define some notations. Right key is assigned +1, left key is assigned âˆ’1. The user strokes is
denoted by ğ‘¢(1. . ğ‘›), and the algorithms predictions (strokes) is defined by ğ‘(1. . ğ‘›), ğ‘› is the current game
turn. ğ‘‡ is the game target.
The predictors can operate on the immediate keystrokes sequence ğ‘¢(1. . ğ‘›), or on the flipping
sequence defined by:
1 ğ‘¢(ğ‘›) == ğ‘¢(ğ‘› âˆ’ 1)
ğ‘“(ğ‘›) = {
âˆ’1
ğ‘’ğ‘™ğ‘ ğ‘’
this sequence indicates flipping of bits, rather than the bits themselves.

3.1.

Predictors

3.1.1. Bias Predictor
The bias predictor tracks the user strokes and searches for specific bias in the sequence (for example
tends to hit more right key). This predictor can be tuned to search for bias in a given history length ğ‘š, this
allows to create multiple predictors each searching for bias with different memory. The expert prediction
is defined by:

ğ‘š

1
ğ‘ƒğµ,ğ‘¢ (ğ‘› + 1) = âˆ‘ ğ‘¢(ğ‘› âˆ’ ğ‘–)
ğ‘š
ğ‘–=1

In my implementation I used four Bias Predictors with memories: ğ‘š = 5, 10, 15, 20.

3.1.2. Flipping Bias Predictor
This essentially the same implementation of the Bias Predictor, but this predictor searches for bias in
flipping sequence (for example hitting the right key ğ‘˜ times followed by ğ‘˜ times left key has zero mean,
but the flipping sequence shows significant bias to hit the same key multiple times). This predictor can
also operate on a given history ğ‘š, such that:
ğ‘š

1
ğ‘ƒğµ,ğ‘“ (ğ‘› + 1) = ğ‘¢(ğ‘›) âˆ‘ ğ‘“(ğ‘› âˆ’ ğ‘–)
ğ‘š
ğ‘–=1

In my implementation I used four Flipping Bias Predictors with memories: ğ‘š = 5, 10, 15, 20.

3.1.3. Pattern Predictor
This predictor detects keystroke patterns (for example [ğ‘…, ğ¿, ğ¿, ğ‘…, ğ¿, ğ¿, â€¦ ] , where ğ‘…, ğ¿ stands for right
and left keys respectively). It searches for pattern length ğ‘š .This predictor operates by the following
procedure:
1.

ğ‘ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘Ÿğ‘› = ğ‘¢(ğ‘› âˆ’ ğ‘š . . ğ‘›)

2.

ğ‘– = ğ‘›, ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¢ = 0

3.

ğ‘¤â„ğ‘–ğ‘™ğ‘’

ğ‘ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘Ÿğ‘› == ğ‘¢(ğ‘– âˆ’ ğ‘š. . ğ‘–)

4.

ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¢ = ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¢ + 1

5.

ğ‘ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘Ÿğ‘› = ğ‘ â„ğ‘–ğ‘“ğ‘¡(ğ‘ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘Ÿğ‘›)

6.

ğ‘– =ğ‘–âˆ’1

7.

end

where ğ‘ â„ğ‘–ğ‘“ğ‘¡(âˆ™) produces a cyclic shift of the input.
The prediction is defined by:
ğ‘ƒğ‘ƒ,ğ‘¢ = ğ‘¢(ğ‘› âˆ’ ğ‘š)

min{ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘¢ , 2ğ‘š}
2ğ‘š

where the score defines the confidence of the prediction, here I defined an ideal case as a situation where
the pattern repeats itself two times.
In my implementation I choose to search for patterns of lengths: ğ‘š = 2,3,4,5,6.

3.1.4. Flipping Pattern Detector
This predictor is implemented exactly as the previous predictor, but it operates on the flipping
sequence instead (it searches for sequences such as: [ğ‘†, ğ‘†, ğ¹, ğ‘†, ğ‘†, ğ¹, â€¦ ], where ğ‘†, ğ¹ stands for same key
and flipping respectively). The scoring algorithm operates exactly the same as the regular pattern
predictor, with replacing the sequence ğ‘¢(1. . ğ‘›) by ğ‘“(1. . ğ‘›), and produces ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘“ . The prediction is then:
min{ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘“ , 2ğ‘š}
ğ‘ƒğ‘ƒ,ğ‘“ = ğ‘¢(ğ‘› âˆ’ ğ‘š)
2ğ‘š

Similar to the previous predictor, the patterns lengths searched for are: ğ‘š = 2,3,4,5,6.

3.1.5. Shannon Inspired Predictor (user reaction predictor)
In his paper, Shannon proposed the user reacts to winning and losing. He proposed the user reactions
can be characterized in 8 ways:
1.
2.
3.
4.
5.
6.
7.
8.

User wins, played the same, wins again, he may play the same of differently.
User wins, played the same, losses, he may play the same of differently.
User wins, played differently, wins again, he may play the same of differently.
User wins, played differently, losses, he may play the same of differently.
User losses, played the same, wins again, he may play the same of differently.
User losses, played the same, losses, he may play the same of differently.
User losses, played differently, wins again, he may play the same of differently.
User losses, played differently, losses, he may play the same of differently.

While previous predictors ignored the winning / losing aspect of the game, this detector introduces
this emotional aspect. In the context of previous predictors, this predictor operates on the flipping
sequence ğ‘“(1. . ğ‘›) and on the user win/loss sequence defined by:
1 ğ‘¢(ğ‘›) â‰  ğ‘(ğ‘›)
ğ‘¤ğ‘¢ (ğ‘›) = {
âˆ’1
ğ‘’ğ‘™ğ‘ ğ‘’
In my implementation I extended the predictor to operate on user with variable memory (Shannonâ€™s
proposal assumed the user has a memory length of ğ‘š = 1), for example the user might have a longer
memory. This predictor is implemented by keeping a state machine to track how the user played the last
time he was in a similar situation, the total number of states is just 22ğ‘š+1 . Here, ğ‘š counts the memory
of results to previous player attempts, and the extra 1 counts first win/loss.
Each time the user plays, the predictor updates the state machine ğ‘†ğ‘š by the following procedure:
1. Based on ğ‘“(ğ‘› âˆ’ ğ‘š âˆ’ 1 â€¦ ğ‘› âˆ’ 1), and ğ‘¤ğ‘¢ (ğ‘› âˆ’ ğ‘š âˆ’ 2 â€¦ ğ‘› âˆ’ 1) map to the appropriate state
index ğ‘–.
2. If ğ‘†ğ‘š (ğ‘–) == 0 then:
%i.e. no meaningful history
(ğ‘–)
ğ‘†ğ‘š = 0.3 ğ‘“(ğ‘›)
%update the state with low score
3. Else if ğ‘†ğ‘š (ğ‘–) ğ‘“(ğ‘›) == 0.3 %i.e. this is the second time the user is doing the same thing
ğ‘†ğ‘š (ğ‘–) = 0.8 ğ‘“(ğ‘›)
%update the state with higher score
4. Else if ğ‘†ğ‘š (ğ‘–) ğ‘“(ğ‘›) == 0.8 %i.e. this is the third time the user is doing the same thing
ğ‘†ğ‘š (ğ‘–) = ğ‘“(ğ‘›)
%update the state with highest score
5. Else
%i.e. the user played different then the prediction
ğ‘†ğ‘š (ğ‘–) = 0
%update the state with zero confidence
The motivation behind these updates is to increase confidence of the decision if the user reacts the
same way as he did previously when encountered a similar situation.
Finally, the prediction of the next step is defined by: ğ‘“(ğ‘› âˆ’ ğ‘š. . ğ‘›), and ğ‘¤ğ‘¢ (ğ‘› âˆ’ ğ‘š âˆ’ 1. . ğ‘›) map to
the appropriate state index ğ‘–, and predicting ğ‘ƒğ‘… (ğ‘› + 1) = ğ‘†ğ‘š (ğ‘–).
In my implementation I choose these memory lengths: ğ‘š = [0,1,2,3]. The ğ‘š = 0 case corresponds
to a user that purely reacts to winning or losing, without memory of what brought the win/loss (for

example whenever losing flip the decision). While the longer memory predictors include the shorter ones,
due to the non-linear update when the user reacted different than expected, the short memory predictors
would react faster to change in behavior.

3.1.6. Hagelbarger's Inspired Predictor (â€œemotionalâ€ bot algorithm)
Hagelbarger proposed a very similar algorithm to Shannonâ€™s, basically, he proposed the machine
should react to winning or losing and play the next step based on the last it encountered such a case.
Essentially this is exactly the same implementation as the previous approach, but operating on the
machineâ€™s strokes and win/loss sequence:
1 ğ‘(ğ‘›) == ğ‘(ğ‘› âˆ’ 1)
ğ‘ğ‘“ (ğ‘›) = {
âˆ’1
ğ‘’ğ‘™ğ‘ ğ‘’
1 ğ‘¢(ğ‘›) == ğ‘(ğ‘›)
ğ‘¤ğ‘ (ğ‘›) = {
âˆ’1
ğ‘’ğ‘™ğ‘ ğ‘’
For this implementation I used the same memory lengths as the previous example.

3.2.

Predictors aggregation, and algorithm decision

There are a total of 26 predictors in my implementation (the number can easily be changed by adding
or removing memory lengths, this can be done in the game_parameters.m file). The predictors results are
aggregated with the exponential weights algorithm. We define an index ğ‘— = 1. . ğ‘ to run over all ğ‘ = 26
predictors, such that ğ‘ƒğ‘— (ğ‘›) is the ğ‘— âˆ’ ğ‘¡â„ expert prediction for time ğ‘›. First we use â€œsoft-maxâ€ to weigh all
the predictors based on their performance:
exp{âˆ’ğœ‚ âˆ‘ğ‘›ğ‘ =1|ğ‘¢(ğ‘ ) âˆ’ ğ‘ƒğ‘— (ğ‘ )|}
ğ‘Šğ‘— (ğ‘› + 1) = ğ‘
âˆ‘ğ‘—=1 exp{âˆ’ğœ‚ âˆ‘ğ‘›ğ‘ =1|ğ‘¢(ğ‘ ) âˆ’ ğ‘ƒğ‘— (ğ‘ )|}
log ğ‘

with: ğœ‚ = âˆš2ğ‘‡âˆ’1 .
This allows to choose a bias for the current decision:
ğ‘

ğ‘ğ‘¡ (ğ‘› + 1) = âˆ‘ ğ‘Šğ‘— (ğ‘› + 1) ğ‘ƒğ‘— (ğ‘› + 1)
ğ‘—=1

Finally, the algorithm takes a random decision with bias ğ‘ğ‘¡ such that:
ğ‘(ğ‘› + 1) = ğ‘…ğ‘ğ‘‘ğ‘’ğ‘šğ‘ğ‘â„ğ‘’ğ‘Ÿ ğ‘¤ğ‘–ğ‘¡â„ ğ‘šğ‘’ğ‘ğ‘› ğ‘ğ‘¡

4. Results
The game was played by several users, here are a couple examples of the final results:

Here are results for a computational random user playing against the algorithm (game target is
500):

We note that the game lasted for almost the maximum duration (997 turns out possible 999), that
the error rate is 50%, and that there is no preferred expert.

5. Brief Code Overview
Here is a short description of the code structure:

1. action.py contains a description of the actions available to each user
2. baseline.py contains an implementation of the baseline algorithm described above
3. bush_mosteller.py contains an implementation of the bush mosteller algorithm
4. player.py contains code for each player, including logic on making a move
5. main.py contains code that wraps everything together

6. Future Work
There are several things to explore in the context of this work:
ï‚·

Predictions:
o The Shannon and Hagelbarger detectors can be implemented on the direct key
strokes sequence.
o All detectors can be explored with other parameters (memory length, ways to score
the predictions).
o It would be interesting to explore other reactive based predictors (how people
respond to winning or losing).
o Reducing the number of experts to expedite learning (decreasing log ğ‘ /2ğ‘‡).

ï‚·

ï‚·

User behaviors:
o It seems that users behave different the first time they play the game and from a (not
statistically meaningful) observation it appears they do better the first time they play.
I suspect this is because they are less engaged the first time, and so can produce more
random sequences.
o It would be interesting to explore and understand how users react to this game, for
example do people have some common behavior model (similar to what Shannon
suggested). Putting this game online can help to evaluate this.
Other ways to perform the task:
o Is it possible to solve this problem in the context of Coverâ€™s algorithm? What are the
desired sequences? Can we learn them from many players?
o If the user produces non-random sequence, it means itâ€™s compressible, that can allow
to predict the next bit.

